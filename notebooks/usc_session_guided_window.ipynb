{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.utils import get_train_test_data\n",
    "from model.hierarchical_self_attention_model import HSA_model_session_guided_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = yaml.load(open('../configs/metadata.yaml', mode='r'), Loader=yaml.FullLoader)\n",
    "\n",
    "metadata_file = open('../configs/metadata.yaml', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/HAR/raw/PAMAP2_Dataset/Protocol\n",
      "../../data/HAR/raw/PAMAP2_Dataset/Protocol\n",
      "../../data/HAR/raw/PAMAP2_Dataset/Protocol\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_train_test_data(dataset='pamap2', holdout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3154, 15, 100, 18)\n",
      "(3154, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_labels = np.repeat(np.expand_dims(y_train, axis=1), repeats=15, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mid = np.repeat(np.expand_dims(y_train, axis=1), repeats=15, axis=1)\n",
    "y_test_mid = np.repeat(np.expand_dims(y_test, axis=1), repeats=15, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 15, 19)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_file = open('../configs/hyperparameters.yaml', mode='r')\n",
    "hyperparameters = yaml.load(hparam_file, Loader=yaml.FullLoader)\n",
    "hparams = hyperparameters['HSA_model']\n",
    "hparams['modality_indices'] = hparams['modality_indices']['pamap2']\n",
    "hparams['n_window'], hparams['n_timesteps'], hparams['n_features'], hparams['n_outputs'] = X_train.shape[1], X_train.shape[2], X_train.shape[3], y_train.shape[1]\n",
    "hparams['n_outputs_window']=19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Physical GPUs, 8 Logical GPUs\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
      "Number of devices: 3\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "device_list = ['/gpu:'+str(i) for i in range(5, 8)]\n",
    "strategy = tf.distribute.MirroredStrategy(devices=device_list)\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "    model = HSA_model_session_guided_window(**hyperparameters['HSA_model']).get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 15, 100, 18) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_window_encoder (MultiWind ((None, None, 64), ( 350720      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "modality_encoder_block_3 (Modal (None, None, 64)     104000      multi_window_encoder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "combined_sensor_self_attention_ ((None, 64), (None,  49856       modality_encoder_block_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           combined_sensor_self_attention_1[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 1, 64)]      0           combined_sensor_self_attention_1[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(0,)]               0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(1,)]               0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 15, 64)]     0           tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 64)]         0           tf_op_layer_Tile[0][0]           \n",
      "                                                                 tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 15, 64)       0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15, 128)      0           multi_window_encoder[0][0]       \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "window_pred (Dense)             (None, 15, 19)       2451        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "session_pred (Dense)            (None, 19)           1235        combined_sensor_self_attention_1[\n",
      "==================================================================================================\n",
      "Total params: 508,262\n",
      "Trainable params: 508,262\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "INFO:tensorflow:batch_all_reduce: 160 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 160 all-reduces with algorithm = nccl, num_packs = 1\n",
      "15/15 [==============================] - 19s 1s/step - loss: 5.4424 - session_pred_accuracy: 0.1071 - window_pred_accuracy: 0.1183 - window_pred_loss: 2.6673 - session_pred_loss: 2.7751 - val_loss: 5.3977 - val_session_pred_accuracy: 0.0506 - val_window_pred_accuracy: 0.0000e+00 - val_window_pred_loss: 2.6935 - val_session_pred_loss: 2.7042\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 11s 712ms/step - loss: 4.9303 - session_pred_accuracy: 0.1092 - window_pred_accuracy: 0.1675 - window_pred_loss: 2.3928 - session_pred_loss: 2.5375 - val_loss: 5.0743 - val_session_pred_accuracy: 0.0000e+00 - val_window_pred_accuracy: 0.1871 - val_window_pred_loss: 2.4650 - val_session_pred_loss: 2.6093\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 11s 713ms/step - loss: 4.1391 - session_pred_accuracy: 0.1998 - window_pred_accuracy: 0.3804 - window_pred_loss: 1.8101 - session_pred_loss: 2.3290 - val_loss: 5.5705 - val_session_pred_accuracy: 0.0506 - val_window_pred_accuracy: 0.1004 - val_window_pred_loss: 2.6267 - val_session_pred_loss: 2.9437\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 11s 710ms/step - loss: 2.5646 - session_pred_accuracy: 0.4986 - window_pred_accuracy: 0.6301 - window_pred_loss: 1.1039 - session_pred_loss: 1.4607 - val_loss: 3.7766 - val_session_pred_accuracy: 0.3418 - val_window_pred_accuracy: 0.4599 - val_window_pred_loss: 1.8495 - val_session_pred_loss: 1.9271\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 11s 714ms/step - loss: 1.2335 - session_pred_accuracy: 0.7865 - window_pred_accuracy: 0.8199 - window_pred_loss: 0.5512 - session_pred_loss: 0.6823 - val_loss: 2.7720 - val_session_pred_accuracy: 0.4367 - val_window_pred_accuracy: 0.5576 - val_window_pred_loss: 1.3179 - val_session_pred_loss: 1.4541\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 11s 711ms/step - loss: 0.7181 - session_pred_accuracy: 0.8862 - window_pred_accuracy: 0.8830 - window_pred_loss: 0.3476 - session_pred_loss: 0.3705 - val_loss: 1.2534 - val_session_pred_accuracy: 0.7848 - val_window_pred_accuracy: 0.7637 - val_window_pred_loss: 0.6627 - val_session_pred_loss: 0.5906\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 11s 715ms/step - loss: 0.4484 - session_pred_accuracy: 0.9415 - window_pred_accuracy: 0.9273 - window_pred_loss: 0.2243 - session_pred_loss: 0.2241 - val_loss: 2.1161 - val_session_pred_accuracy: 0.6582 - val_window_pred_accuracy: 0.6426 - val_window_pred_loss: 0.9912 - val_session_pred_loss: 1.1249\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 11s 717ms/step - loss: 0.3321 - session_pred_accuracy: 0.9563 - window_pred_accuracy: 0.9448 - window_pred_loss: 0.1685 - session_pred_loss: 0.1637 - val_loss: 1.5983 - val_session_pred_accuracy: 0.6804 - val_window_pred_accuracy: 0.7300 - val_window_pred_loss: 0.7389 - val_session_pred_loss: 0.8594\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 11s 710ms/step - loss: 0.2823 - session_pred_accuracy: 0.9623 - window_pred_accuracy: 0.9569 - window_pred_loss: 0.1384 - session_pred_loss: 0.1438 - val_loss: 1.4802 - val_session_pred_accuracy: 0.7532 - val_window_pred_accuracy: 0.7171 - val_window_pred_loss: 0.7751 - val_session_pred_loss: 0.7051\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 11s 710ms/step - loss: 0.3008 - session_pred_accuracy: 0.9563 - window_pred_accuracy: 0.9525 - window_pred_loss: 0.1483 - session_pred_loss: 0.1525 - val_loss: 1.6031 - val_session_pred_accuracy: 0.7152 - val_window_pred_accuracy: 0.6827 - val_window_pred_loss: 0.7824 - val_session_pred_loss: 0.8207\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 11s 713ms/step - loss: 0.2637 - session_pred_accuracy: 0.9641 - window_pred_accuracy: 0.9620 - window_pred_loss: 0.1298 - session_pred_loss: 0.1339 - val_loss: 2.5179 - val_session_pred_accuracy: 0.7595 - val_window_pred_accuracy: 0.7243 - val_window_pred_loss: 1.1646 - val_session_pred_loss: 1.3533\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 11s 712ms/step - loss: 0.2130 - session_pred_accuracy: 0.9729 - window_pred_accuracy: 0.9685 - window_pred_loss: 0.1039 - session_pred_loss: 0.1090 - val_loss: 2.1371 - val_session_pred_accuracy: 0.7215 - val_window_pred_accuracy: 0.7184 - val_window_pred_loss: 0.9307 - val_session_pred_loss: 1.2064\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 11s 707ms/step - loss: 0.1964 - session_pred_accuracy: 0.9708 - window_pred_accuracy: 0.9713 - window_pred_loss: 0.0943 - session_pred_loss: 0.1020 - val_loss: 0.5967 - val_session_pred_accuracy: 0.8038 - val_window_pred_accuracy: 0.8669 - val_window_pred_loss: 0.2805 - val_session_pred_loss: 0.3162\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1859 - session_pred_accuracy: 0.9718 - window_pred_accuracy: 0.9678 - window_pred_loss: 0.0952 - session_pred_loss: 0.0907"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, [y_train_mid, y_train], batch_size=len(device_list) * 64, epochs=40, validation_split=0.1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mid, pred_sess = model.predict(X_test, batch_size=len(device_list) * 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {1:'lying',2:'sitting',3:'standing',4:'walking',5:'running',6:'cycling',7:'Nordic walking',\n",
    "              11:'ascending stairs',12:'descending stairs',13:'vacuum cleaning',\n",
    "              14:'ironing', 18:'rope jumping'}\n",
    "class_names = list(labels_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       0.85      0.93      0.89        44\n",
      "           3       0.93      0.85      0.89        46\n",
      "           4       1.00      1.00      1.00        49\n",
      "           5       1.00      1.00      1.00        43\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        51\n",
      "          11       1.00      1.00      1.00        22\n",
      "          12       0.56      1.00      0.72        18\n",
      "          13       1.00      0.47      0.64        40\n",
      "          14       0.91      1.00      0.95        73\n",
      "\n",
      "    accuracy                           0.93       468\n",
      "   macro avg       0.93      0.93      0.92       468\n",
      "weighted avg       0.95      0.93      0.93       468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred_sess, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "activity_map = json.load(open(os.path.join('..','data', 'activity_maps', 'pamap2_activity.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'lying',\n",
       " '2': 'sitting',\n",
       " '3': 'standing',\n",
       " '4': 'walking',\n",
       " '5': 'running',\n",
       " '6': 'cycling',\n",
       " '7': 'Nordic walking',\n",
       " '11': 'ascending stairs',\n",
       " '12': 'descending stairs',\n",
       " '13': 'vacuum cleaning',\n",
       " '14': 'ironing',\n",
       " '18': 'rope jumping'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (11, 11), indices imply (12, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1661\u001b[0m                 blocks = [\n\u001b[0;32m-> 1662\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m                 ]\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 11, placement implies 12",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-02cfc33325f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mactivity_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivity_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivity_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"YlGnBu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (11, 11), indices imply (12, 12)"
     ]
    }
   ],
   "source": [
    "confm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(pred_sess, axis=1))\n",
    "activity_list = list(activity_map.values())\n",
    "df_cm = pd.DataFrame(confm, index=activity_list, columns=activity_list)\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.75       779\n",
      "           1       0.91      0.94      0.92       390\n",
      "           2       0.93      0.94      0.93       390\n",
      "           3       0.92      0.93      0.93       390\n",
      "           4       0.93      0.92      0.93       390\n",
      "           5       0.92      0.92      0.92       388\n",
      "           6       0.93      0.92      0.92       388\n",
      "           7       0.82      0.93      0.87       390\n",
      "           8       0.93      0.94      0.93       392\n",
      "           9       0.94      0.93      0.93       392\n",
      "          10       0.93      0.94      0.94       391\n",
      "          11       0.93      0.93      0.93       391\n",
      "          12       0.93      0.94      0.93       391\n",
      "          13       0.94      0.94      0.94       390\n",
      "          14       0.79      0.94      0.86       390\n",
      "          15       0.92      0.94      0.93       390\n",
      "          16       0.82      0.93      0.88       389\n",
      "          17       0.79      0.95      0.86       389\n",
      "\n",
      "    accuracy                           0.90      7410\n",
      "   macro avg       0.90      0.92      0.91      7410\n",
      "weighted avg       0.91      0.90      0.90      7410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test_mid.reshape(-1, 18), axis=1), np.argmax(pred_mid.reshape(-1, 18), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_activity_opp = ['Other', 'Open Door 1', 'Open Door 2', 'Close Door 1',\n",
    "                    'Close Door 2', 'Open Fridge', 'Close Fridge', \n",
    "                    'Open Dishwasher', 'Close Dishwasher', 'Open Drawer 1', \n",
    "                    'Close Drawer 1', 'Open Drawer 2', 'Close Drawer 2', \n",
    "                    'Open Drawer 3', 'Close Drawer 3', 'Clean Table', \n",
    "                    'Drink from Cup', 'Toggle Switch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
