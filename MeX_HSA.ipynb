{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MeX-HSA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOiAfc12eluHIYH5HXYfXFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saif-M-Dhrubo/hierarchical-attention-HAR/blob/master/MeX_HSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfBMqHybvs62",
        "colab_type": "code",
        "outputId": "3081ad22-d82d-4d01-e451-a19925dc7e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKkoLUaArmEH",
        "colab_type": "code",
        "outputId": "2314aa0b-8b5d-46cd-f3a5-50ad5395de34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 15 13:52:04 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rGypAtJjQp-",
        "colab_type": "text"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycknxWdWjVWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q -O clean_mex_data.csv https://www.dropbox.com/s/h22cg25jszu2360/clean_mex_data.csv?dl=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtDOeeL6kYEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('clean_mex_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRKFZhUQ-7hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7256baf1-a396-40e5-ebe4-b80a25c00ba9"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act_x</th>\n",
              "      <th>act_y</th>\n",
              "      <th>act_z</th>\n",
              "      <th>acw_x</th>\n",
              "      <th>acw_y</th>\n",
              "      <th>acw_z</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "      <td>1.229839e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-3.634968e-02</td>\n",
              "      <td>1.152776e-02</td>\n",
              "      <td>-6.681068e-03</td>\n",
              "      <td>-4.363667e-02</td>\n",
              "      <td>-2.697961e-02</td>\n",
              "      <td>-1.545097e-01</td>\n",
              "      <td>1.547600e+01</td>\n",
              "      <td>3.968074e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.216871e-01</td>\n",
              "      <td>5.930078e-01</td>\n",
              "      <td>4.384600e-01</td>\n",
              "      <td>5.172970e-01</td>\n",
              "      <td>5.657868e-01</td>\n",
              "      <td>6.308799e-01</td>\n",
              "      <td>8.655481e+00</td>\n",
              "      <td>1.984015e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.453125e+00</td>\n",
              "      <td>-4.015625e+00</td>\n",
              "      <td>-2.380208e+00</td>\n",
              "      <td>-8.000000e+00</td>\n",
              "      <td>-8.000000e+00</td>\n",
              "      <td>-6.078125e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-5.781250e-01</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-2.343750e-01</td>\n",
              "      <td>-4.375000e-01</td>\n",
              "      <td>-4.218750e-01</td>\n",
              "      <td>-7.500000e-01</td>\n",
              "      <td>8.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.687500e-02</td>\n",
              "      <td>-1.562500e-02</td>\n",
              "      <td>1.562500e-02</td>\n",
              "      <td>-7.812500e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.968750e-01</td>\n",
              "      <td>1.500000e+01</td>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.625000e-01</td>\n",
              "      <td>5.937500e-01</td>\n",
              "      <td>2.031250e-01</td>\n",
              "      <td>3.750000e-01</td>\n",
              "      <td>1.875000e-01</td>\n",
              "      <td>4.062500e-01</td>\n",
              "      <td>2.300000e+01</td>\n",
              "      <td>6.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.484375e+00</td>\n",
              "      <td>1.656250e+00</td>\n",
              "      <td>4.187500e+00</td>\n",
              "      <td>7.953125e+00</td>\n",
              "      <td>7.984375e+00</td>\n",
              "      <td>7.984375e+00</td>\n",
              "      <td>3.000000e+01</td>\n",
              "      <td>7.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              act_x         act_y  ...    subject_id      activity\n",
              "count  1.229839e+06  1.229839e+06  ...  1.229839e+06  1.229839e+06\n",
              "mean  -3.634968e-02  1.152776e-02  ...  1.547600e+01  3.968074e+00\n",
              "std    6.216871e-01  5.930078e-01  ...  8.655481e+00  1.984015e+00\n",
              "min   -3.453125e+00 -4.015625e+00  ...  1.000000e+00  1.000000e+00\n",
              "25%   -5.781250e-01 -5.000000e-01  ...  8.000000e+00  2.000000e+00\n",
              "50%   -4.687500e-02 -1.562500e-02  ...  1.500000e+01  4.000000e+00\n",
              "75%    5.625000e-01  5.937500e-01  ...  2.300000e+01  6.000000e+00\n",
              "max    2.484375e+00  1.656250e+00  ...  3.000000e+01  7.000000e+00\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJNRewat_Rsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURES = ['act_x', 'act_y', 'act_z', 'acw_x', 'acw_y', 'acw_z']\n",
        "LABELS = 'activity'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7265KU_-2Pi",
        "colab_type": "text"
      },
      "source": [
        "### scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz0NtJiW_L8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[FEATURES] = scaler.fit_transform(df[FEATURES])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2VKsiuZ_IoQ",
        "colab_type": "text"
      },
      "source": [
        "### Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJmQmda4kvFl",
        "colab_type": "code",
        "outputId": "94a14249-be2e-471c-e78f-7e6af7780779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "sns.countplot(x='subject_id', data=df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01d0b02cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEHCAYAAACEKcAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAaoElEQVR4nO3de9RcZX3o8e+PhJso1wSEBBpag5Za5ZJyOWpVOEK4aASDYlUigrQYRLSeirVLUeQcOFovVAqLxV2pFEEKKhoiip6eJZdEMBBQiYolCCSCgC0KJ/g7f+znheF9Z/ZMspl538n7/aw1a/Z+9m8/88w8M/Obvfcze0dmIknSutpgvBsgSRpuJhJJUiMmEklSIyYSSVIjJhJJUiNTx7sBgzZt2rScNWvWeDdDkobG0qVLf52Z0zstn3SJZNasWSxZsmS8myFJQyMiflm33F1bkqRGTCSSpEZMJJKkRkwkkqRGTCSSpEZMJJKkRkwkkqRGTCSSpEZMJJKkRibdP9uH0Q/OPbRrzL7HfX0ALZGksdwikSQ1YiKRJDViIpEkNWIikSQ14sH2Se6KC+d2jZl/9LcG0BJJw8otEklSIyYSSVIj7trSUDn6qu674i48zF1x0iC5RSJJamRSbpGsPvtLXWOmH//2AbREkobfpEwkmhwOunph15hvzjtrAC2R1m/u2pIkNWIikSQ1YiKRJDXiMRJJA3PiVfd2jTnzsB0H0BI9l9wikSQ1YiKRJDXiri1JWo88eOYNXWO2O/E1z+ljmkgkaRw88OkVXWNe+MEXDaAlzblrS5LUiFskksY47Mp/r11+1ZteOaCWaBi4RSJJasQtki5WnXNm15ht/+bEAbREE8khX+3+vvjG4ZPjfXHElcu6xnzlTS8bQEvWXw9+bmnXmO1O2nMALWnPRCJJNW49b1Xt8t2P3fbp6Xs+90DX+mad9MLGbZpo+p5IImIKsAS4LzMPjYidgcuAbYClwDsy88mI2Bi4BNgTeAh4S2beU+r4MHAM8BRwYmYuKuVzgc8DU4DzMvP0fj8faW0dcuV5XWO+8aZjB9ASqT8GsUXyPuAuYPMyfwbw2cy8LCLOoUoQZ5f732TmiyLiyBL3lojYFTgS+DNgB+DbEbFLqess4HXASuCWiLgmM+8cwHOSNIF89Ypfd405fP60AbRkcuprIomImcAhwGnAByIigP2AvyohFwOnUCWSeWUa4ArgCyV+HnBZZj4B/CIiVgB7lbgVmfnz8liXlVgTidbJwVd9smvMtYf9wwBaIg2Xfm+RfA74O+AFZX4b4JHMXFPmVwIzyvQM4F6AzFwTEY+W+BnAjS11tq5z76jyvds1IiKOA44D2GmnnRo8nYlv0fkHd4058JhrB9ASqZmzrnqwa8zCw7YbQEvUTd8SSUQcCqzKzKUR8Zp+PU4vMvNc4FyAOXPm5Hi2ZbI489IDu8ac+LZFA2jJcDn0iku7xnx9/tsAeP0VX+0a+7X5hwMw74pvdY29ev7crjFSO/3cInkF8IaIOBjYhOoYyeeBLSNiatkqmQncV+LvA3YEVkbEVGALqoPuI+UjWtfpVC5JbX330tVdY177tukDaMn6o29/SMzMD2fmzMycRXWw/DuZ+Tbgu8D8ErYAuLpMX1PmKcu/k5lZyo+MiI3LiK/ZwM3ALcDsiNg5IjYqj3FNv56PJKm98fgfyYeAyyLik8CtwPml/Hzgi+Vg+sNUiYHMXB4Rl1MdRF8DLMzMpwAi4gRgEdXw3wsyc/lAn4kkaTCJJDNvAG4o0z/nmVFXrTG/B47osP5pVCO/RpdfC3jkWJLWwaqzvtY1ZtuFr+8a4z/b1bMLLz6ga8zRC64bQEskTSQmEo27Uy7vPsLrlDc7wkuaqDz7rySpEROJJKkRE4kkqRETiSSpEROJJKkRE4kkqRGH/z6HfnXWB7rG7LDwMwD8+Kx5XWNfsvDqrjGSNN7cIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDViIpEkNWIikSQ1YiKRJDXSt0QSEZtExM0R8aOIWB4RHy/lO0fETRGxIiL+NSI2KuUbl/kVZfmslro+XMp/EhEHtpTPLWUrIuLkfj0XSVJn/dwieQLYLzNfDuwGzI2IfYAzgM9m5ouA3wDHlPhjgN+U8s+WOCJiV+BI4M+AucA/R8SUiJgCnAUcBOwKvLXESpIGqG+JJCv/WWY3LLcE9gOuKOUXA28s0/PKPGX5/hERpfyyzHwiM38BrAD2KrcVmfnzzHwSuKzESpIGqK/HSMqWw23AKmAx8DPgkcxcU0JWAjPK9AzgXoCy/FFgm9byUet0Km/XjuMiYklELFm9evVz8dQkSUVfE0lmPpWZuwEzqbYgXtLPx6tpx7mZOScz50yfPn08miBJ662BjNrKzEeA7wL7AltGxNSyaCZwX5m+D9gRoCzfAniotXzUOp3KJUkD1M9RW9MjYssyvSnwOuAuqoQyv4QtAK4u09eUecry72RmlvIjy6iunYHZwM3ALcDsMgpsI6oD8tf06/lIktqb2j1knW0PXFxGV20AXJ6ZX4+IO4HLIuKTwK3A+SX+fOCLEbECeJgqMZCZyyPicuBOYA2wMDOfAoiIE4BFwBTggsxc3sfnI0lqo2+JJDOXAbu3Kf851fGS0eW/B47oUNdpwGltyq8Frm3cWEnSOvOf7ZKkRkwkkqRGTCSSpEZMJJKkRkwkkqRGTCSSpEZMJJKkRkwkkqRGekokEXF9L2WSpMmn9p/tEbEJ8DxgWkRsBURZtDkdTtkuSZpcup0i5a+Bk4AdgKU8k0geA77Qx3ZJkoZEbSLJzM8Dn4+I92bmPw2oTZKkIdLTSRsz858i4r8Bs1rXycxL+tQuSdKQ6CmRRMQXgT8BbgOeKsUJmEgkaZLr9TTyc4Bdy4WmJEl6Wq//I7kDeGE/GyJJGk69bpFMA+6MiJuBJ0YKM/MNfWmVJGlo9JpITulnIyRJw6vXUVvf63dDJEnDqddRW7+lGqUFsBGwIfBfmbl5vxomSRoOvW6RvGBkOiICmAfs069GSZKGx1qf/Tcr/wYc2If2SJKGTK+7tg5vmd2A6n8lv+9LiyRJQ6XXUVuvb5leA9xDtXtLkjTJ9XqM5Oh+N0SSNJx6vbDVzIi4KiJWlduVETGz342TJE18vR5svxC4huq6JDsAXytlkqRJrtdEMj0zL8zMNeV2ETC9j+2SJA2JXhPJQxHx9oiYUm5vBx7qZ8MkScOh10TyLuDNwAPA/cB84J19apMkaYj0Ovz3E8CCzPwNQERsDXyaKsFIkiaxXrdIXjaSRAAy82Fg9/40SZI0THpNJBtExFYjM2WLpNetGUnSeqzXZPCPwA8i4itl/gjgtP40SZI0THr9Z/slEbEE2K8UHZ6Zd/avWZKkYdHz2X8z887M/EK5dU0iEbFjRHw3Iu6MiOUR8b5SvnVELI6Iu8v9VqU8IuLMiFgREcsiYo+WuhaU+LsjYkFL+Z4RcXtZ58xyintJ0gCt9Wnk18Ia4G8zc1eqa5csjIhdgZOB6zNzNnB9mQc4CJhdbscBZ8PTx2M+BuwN7AV8rOV4zdnAu1vWm9vH5yNJaqNviSQz78/MH5bp3wJ3ATOozhp8cQm7GHhjmZ4HXFKud3IjsGVEbE913ZPFmflwGTm2GJhblm2emTdmZgKXtNQlSRqQfm6RPC0iZlENF74J2C4z7y+LHgC2K9MzgHtbVltZyurKV7YplyQNUN8TSUQ8H7gSOCkzH2tdVrYksu2Kz20bjouIJRGxZPXq1f1+OEmaVPqaSCJiQ6okcmlmfrUUP1h2S1HuV5Xy+4AdW1afWcrqyme2KR8jM8/NzDmZOWf6dM81KUnPpb4lkjKC6nzgrsz8TMuia4CRkVcLgKtbyo8qo7f2AR4tu8AWAQdExFblIPsBwKKy7LGI2Kc81lEtdUmSBqSf/05/BfAO4PaIuK2U/T1wOnB5RBwD/JLqZJAA1wIHAyuAx4GjoTodS0ScCtxS4j5RTtEC8B7gImBT4JvlJkkaoL4lksz8d6DT/zr2bxOfwMIOdV0AXNCmfAnw0gbNlCQ1NJBRW5Kk9ZeJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktSIiUSS1IiJRJLUiIlEktRI3xJJRFwQEasi4o6Wsq0jYnFE3F3utyrlERFnRsSKiFgWEXu0rLOgxN8dEQtayveMiNvLOmdGRPTruUiSOuvnFslFwNxRZScD12fmbOD6Mg9wEDC73I4DzoYq8QAfA/YG9gI+NpJ8Ssy7W9Yb/ViSpAHoWyLJzO8DD48qngdcXKYvBt7YUn5JVm4EtoyI7YEDgcWZ+XBm/gZYDMwtyzbPzBszM4FLWuqSJA3QoI+RbJeZ95fpB4DtyvQM4N6WuJWlrK58ZZvytiLiuIhYEhFLVq9e3ewZSJKeZdwOtpctiRzQY52bmXMyc8706dMH8ZCSNGkMOpE8WHZLUe5XlfL7gB1b4maWsrrymW3KJUkDNuhEcg0wMvJqAXB1S/lRZfTWPsCjZRfYIuCAiNiqHGQ/AFhUlj0WEfuU0VpHtdQlSRqgqf2qOCK+DLwGmBYRK6lGX50OXB4RxwC/BN5cwq8FDgZWAI8DRwNk5sMRcSpwS4n7RGaOHMB/D9XIsE2Bb5abJGnA+pZIMvOtHRbt3yY2gYUd6rkAuKBN+RLgpU3aKElqzn+2S5IaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGjGRSJIaMZFIkhoxkUiSGhn6RBIRcyPiJxGxIiJOHu/2SNJkM9SJJCKmAGcBBwG7Am+NiF3Ht1WSNLkMdSIB9gJWZObPM/NJ4DJg3ji3SZImlcjM8W7DOouI+cDczDy2zL8D2DszTxgVdxxwXJl9MfCTUVVNA37d48P2K3aitGMixE6UdkyE2InSjokQO1HaMWyxz0Xdf5SZ0zuukZlDewPmA+e1zL8D+MI61LNkvGMnSjsmQuxEacdEiJ0o7ZgIsROlHcMW2++6M3Pod23dB+zYMj+zlEmSBmTYE8ktwOyI2DkiNgKOBK4Z5zZJ0qQydbwb0ERmromIE4BFwBTggsxcvg5VnTsBYidKOyZC7ERpx0SInSjtmAixE6Udwxbb77qH+2C7JGn8DfuuLUnSODORSJKaWdthXuvTDbgAWAXc0UPsjsB3gTuB5cD7amI3AW4GflRiP95D/VOAW4Gvd4m7B7gduI0ehukBWwJXAD8G7gL27RD34lLnyO0x4KSaet9fntsdwJeBTWpi31filo+us10fAFsDi4G7y/1WXeKPKHX/AZjTJfZT5bVYBlwFbFkTe2qJuw24Dtih2/sG+FsggWk19Z5CNbpw5LU+uK5e4L2lzcuB/11T77+21HkPcFuX12I34MaR9xKwV03sy4EflPfe14DN6z4X7fqwJnZM/9XEjum/mtgx/dcptl3/1dTbqf861j26D2vqHtOHNbFj+q8mdkz/0eF7CtgZuAlYUdqzUdfvmbX54l3fbsBfAnvQWyLZHtijTL8A+Cmwa4fYAJ5fpjcsnbJPl/o/APwLvSWSaWvxHC8Gji3TG1G+OLusMwV4gOpPSO2WzwB+AWxa5i8H3tkh9qVUSeR5VIM7vg28qK4Pygft5DJ9MnBGl/g/pUqEN/DsRNIu9gBgapk+Y6TuDrGbt0yfCJxT974pH+JFwC95JpG0q/cU4IO9vB+B15bXbOMyv20v713gH4GPdqn7OuCgMn0wcENN7C3Aq8v0u4BT6z4X7fqwJnZM/9XEjum/mtgx/dcptl3/1dTbqf86xY/pw7p2jO7DmnrH9F9N7Jj+o8P3FNXn+chSfg5wfLfvjEm9ayszvw883GPs/Zn5wzL9W6pf9zM6xGZm/meZ3bDcOo5qiIiZwCHAeb23vruI2ILqS+H80q4nM/ORHlbdH/hZZv6yJmYqsGlETKVKEr/qEPenwE2Z+XhmrgG+Bxw+srBDH8yjSoCU+zfWxWfmXZk5+mwFnWKvK+2A6tfczJrYx1pmN6P0Yc375rPA39HS12v5HmsXezxwemY+UWJWdas3IgJ4M9WWYl3dSfXLFGALSh92iN0F+H6ZXgy8qcR2+lyM6cNOse36ryZ2TP/VxI7pvy6f42f139p85rvEj+nDbnW39mFN7Jj+q4kd038131P7Ue3FgFGfv04mdSJZVxExC9idKoN3ipkSEbdR7SJYnJkdY4HPUb2B/9DDwydwXUQsLad+qbMzsBq4MCJujYjzImKzHh7jSFq+hMY0IPM+4NPAfwD3A49m5nUdwu8AXhUR20TE86h+Oe3YIXbEdpl5f5l+ANiuhzavi3cB36wLiIjTIuJe4G1Uvw47xc0D7svMH/X42CdExLKIuCAitqqJ24Xq9bspIr4XEX/RQ92vAh7MzLu7xJ0EfKo8v08DH66JXc4z57E7gjZ9OOpzUduHvXyGeogd03+jY+v6rzW2W/+1aUNt/42Kr+3DDs+vbR+Oiq3tv1Gxbftv9PcU8DPgkZZkvZKa5DnCRLKWIuL5wJVU+/of6xSXmU9l5m5Uv3j3ioiXdqjvUGBVZi7tsQmvzMw9qM54vDAi/rImdirVLoqzM3N34L+odjN0VP7Y+QbgKzUxW1G9KXem2u+8WUS8vV1sZt5FtfvhOuBbVPtzn6prw6j1k5qtuXUVER8B1gCXdnn8j2TmjiXuhHYxJUH+PTWJZpSzgT+h2sd9P9UujE6mUh1v2Af4H8Dl5ddqnbdS80OgxfHA+8vzez9ly7WDdwHviYilVLtMnmxdWPe5GN2HvX6G6mLb9V+72E791xpb6unYf23qre2/NvEd+7DmtRjTh21iO/Zfm9i2/Tf6ewp4SbvXoKtu+77W9xswix6OkeQz+xEXAR9Yy8f4KG32qZZl/4sq699D9cvtceBLPdZ7Sqd6y/IXAve0zL8K+EaXOucB13WJOQI4v2X+KOCfe2zz/wTeU9cHVCfV3L5Mbw/8pJc+Y9Qxkk6xwDupDjw+r9f3ArDTqDY+HQv8OdUvunvKbQ3V1toLe6h39HMfPf8t4LUt8z8Dptc8t6nAg1S7fLo91qM881+yAB7r8bXYBbi57nPRqQ/bxXbqv06x7fqvrt7R/Tc6tq7/eqh39Gva7rVo24c1z29MH3aot23/9dDmZ/VfS/lHqRLdr3nmONS+wKJun2u3SHpUfkGcD9yVmZ/pEjs9IrYs05sCr6MasTFGZn44M2dm5iyqXUrfycy2v+4jYrOIeMHINNWBxzs6tSMzHwDujYgXl6L9qUZz1Onl1+x/APtExPPK67I/1b7YtiJi23K/E9XxkX/pUv81wIIyvQC4ukt8zyJiLtVuxDdk5uNdYme3zM6jcx/enpnbZuas0o8rqQ54PtCh3u1bZg+jpg+Bf6M6WEtE7EI1YKLuLK7/HfhxZq6siRnxK+DVZXo/qhFWbbX04QbAP1AdhK37XIzpw7X8DLWNbdd/NbFj+q9dbKf+o/oyb1dv2/6reX6d+rDTa/GsPqypd0z/1bwWY/qvw/fUXVSjvuaXVXv7/HXLNOvzjeoL837g/1G9eY6piX0l1eb5yHDCp4f9tYl9GdVQ3mXlTfbRHtvzGmpGbQF/TDVUb2S43kd6qHM3qqGBy6je0FvVxG4GPARs0UO9H6f6Yr0D+CJlREqH2P9DlcB+BOzfrQ+AbYDrqb7Yvg1s3SX+sDL9BNWHf1FN7Arg3pY+PKcm9sry/JZRDZmc0cv7hpaRdR3q/SLVMMxlVF+429fEbgR8qbTjh8B+dW0ALgL+ppf3OtV7emnpl5uAPWti30c1AuinwOk880u47eeiXR/WxI7pv5rYMf1XEzum/zrFtuu/mno79V+n+DF9WNeO0X1YU++Y/quJHdN/dPieovqeubm81l+h5rM9cvMUKZKkRty1JUlqxEQiSWrERCJJasREIklqxEQiSWrERCJJasREIj3HIuKUiPhgm/IdIuKKduv0UOc7I2KHLjHnRcSuHdb9wro8rtSLob5muzRMMvNXPPOP4bX1Tqo/jXU6yzKZeew61i014haJ1INyeppvRMSPIuKOiHhLRNwTEdPK8jkRcUPLKi+PiB9ExN0R8e4SMysiRk6nMSUiPhURt5SzyP51y2N9KCJuL491ekTMB+YAl0bEbeV0Fu3aeENEzCnTR0fETyPiZuAVfXlRpMItEqk3c6mu93AIPH2tlzNq4l9GdbbXzYBbI+Ibo5YfQ3X6/b+IiI2B/xsR11GdfXUesHdmPh4RW2fmwxFxAtUJOpd0a2g5F9THqU6Z8SjVuZNuXZsnK60Nt0ik3twOvC4izoiIV2Xmo13ir87M32Xmr6m+yPcatfwA4KhyLYibqM5NNZvqhH0XZjkhYWb2dFGsUfamutrh6sx8kupyqVLfuEUi9SAzfxoRe1CdAO+TEXE91enGR36MbTJ6lS7zAbw3Mxc9qzDiwOeoydLAuEUi9aCMmHo8M78EfIrqNOP3UO0+gnLp2RbzImKTiNiG6qzOt4xavgg4PiI2LPXvUi4NsBg4ulwsi4jYusT/luqCRL24CXh1VFel3JDq+jFS37hFIvXmz6kua/oHqtOrHw9sCpwfEadSXZSp1TKqXVrTgFMz81dRXfp0ZMvkPKqLIv2wXENiNdV1zb8VEbsBSyLiSeBaqqv3XUR1DYnfAftm5u86NTQz74+IU6gu/vQI1anEpb7xNPLSgETEnsBnMvPVXYOlIeKuLWkAyrDcLwOfH++2SM81t0ikIRMRVwE7jyr+0OgD99KgmEgkSY24a0uS1IiJRJLUiIlEktSIiUSS1Mj/BxNa9ZcZH/ImAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAjSc3rWlbr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sub = list(range(1,25))\n",
        "val_sub = list(range(26,31))\n",
        "test_sub = list(range(26,31))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfZHmcyrlYnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = df[df['subject_id'].isin(train_sub)]\n",
        "val_df =  df[df['subject_id'].isin(val_sub)]\n",
        "test_df = df[df['subject_id'].isin(test_sub)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaMWdcf3vwfJ",
        "colab_type": "text"
      },
      "source": [
        "## windowing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QALnFkkvyZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_windowed_dataset(df, features= FEATURES, class_label = LABELS, window_size=1000, stride = 500):\n",
        "    X = df[features].values\n",
        "    y = df[class_label].values\n",
        "    segments = []\n",
        "    labels = []\n",
        "    # segments = np.zeros(((len(X)//(window_size//2))-1,window_size,len(features)))\n",
        "    # labels = np.zeros(((len(y)//(window_size//2))-1))\n",
        "    current_idx = 0\n",
        "\n",
        "    seg_start= 0\n",
        "    seg_end = window_size\n",
        "    while seg_end <= len(X):\n",
        "        segments.append(X[seg_start:seg_end])\n",
        "        labels.append(stats.mode(y[seg_start:seg_end])[0])\n",
        "\n",
        "        seg_start += stride\n",
        "        seg_end = seg_start + window_size\n",
        "\n",
        "    return np.asarray(segments).astype(np.float32), np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYp9TZAfrk-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = create_windowed_dataset(train_df, window_size=1000, stride = 250)\n",
        "X_val, y_val = create_windowed_dataset(val_df, window_size=1000, stride = 250)\n",
        "X_test, y_test = create_windowed_dataset(test_df, window_size=1000, stride = 250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cdjygkru1SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], 40, 25, 6))\n",
        "X_val = X_val.reshape((X_val.shape[0], 40, 25, 6))\n",
        "X_test = X_test.reshape((X_test.shape[0], 40, 25, 6))\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train-1)\n",
        "y_val = tf.keras.utils.to_categorical(y_val-1)\n",
        "y_test = tf.keras.utils.to_categorical(y_test-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAFv2LTXwtAD",
        "colab_type": "code",
        "outputId": "5a1bb463-9f46-4f7b-b136-1f2ad994e99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3931, 40, 25, 6)\n",
            "(3931, 7)\n",
            "(818, 40, 25, 6)\n",
            "(818, 7)\n",
            "(818, 40, 25, 6)\n",
            "(818, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhRBTzCt50jV",
        "colab_type": "text"
      },
      "source": [
        "## tf data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j_NC1-q5y7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHDhgq3G7JiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "# SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset = val_dataset.batch(16, drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP8sVlP9rirJ",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGlJDgDrZrHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model, include_dropout=True, dropout_rate=0.2):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "        self.include_dropout = include_dropout\n",
        "        if include_dropout:\n",
        "            self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model)\n",
        "        # apply sin to even index in the array\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        # apply cos to odd index in the array\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
        "        if self.include_dropout:\n",
        "            x = self.dropout(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYT3Tbh4QhnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead) \n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model,use_bias=False)\n",
        "        self.wk = tf.keras.layers.Dense(d_model,use_bias=True)\n",
        "        self.wv = tf.keras.layers.Dense(d_model,use_bias=True)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, \n",
        "                                        (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "            \n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "    ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odawothQxCMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AggregateAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(AggregateAttention, self).__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.d_model = d_model\n",
        "        self.query = self.add_weight(\"learned_query\",shape=[1, 1, self.d_model])\n",
        "\n",
        "    # def build(self, input_shape):\n",
        "        # initializer=tf.keras.initializers.Orthogonal()\n",
        "        \n",
        "    \n",
        "    def call(self, v, k):\n",
        "        # batched_query = tf.tile(self.query, [tf.shape(v)[0],1])\n",
        "        batched_query = tf.tile(self.query, [tf.shape(v)[0],1,1])\n",
        "        output, attention_weights = self.mha(v, k, batched_query, mask=None)\n",
        "        output = tf.squeeze(output, axis=1)\n",
        "        attention_weights = tf.squeeze(attention_weights, axis=2)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tf.TensorShape([input_shape[0], self.d_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syJtH2GUhVTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AggregateAttentionBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(AggregateAttentionBlock, self).__init__()\n",
        "        self.aga = AggregateAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        attn_output, attn_scores = self.aga(x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        \n",
        "        ffn_output = self.ffn(attn_output)  # (batch_size, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out = self.layernorm(ffn_output + attn_output)  # (batch_size, d_model)\n",
        "        return out, attn_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg1dh_ajyO8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SelfAttentionBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(SelfAttentionBlock, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask=None):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXotyreEfoNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_timesteps, d_model, num_heads, dff, num_sa_blocks=1, add_pe=True, dropout_rate=0.1):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.add_pe = add_pe\n",
        "        self.pe = PositionalEncoding(n_timesteps, d_model)\n",
        "        self.self_attn_blocks = tf.keras.Sequential(\n",
        "            [SelfAttentionBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_sa_blocks)]\n",
        "            )\n",
        "        self.attn_aggr = AggregateAttentionBlock(d_model, num_heads, dff, dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        if self.add_pe:\n",
        "            x = self.pe(x)\n",
        "        x = self.self_attn_blocks(x)\n",
        "        x, _  = self.attn_aggr(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHIYaBr4ZvCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HSAEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_window, n_timesteps, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super(HSAEncoder, self).__init__()\n",
        "        self.window_encoder = EncoderBlock(n_timesteps, d_model, num_heads,\n",
        "                                           dff, num_sa_blocks=2, add_pe=False, \n",
        "                                           dropout_rate=dropout_rate)\n",
        "        self.window_sequence = tf.keras.layers.TimeDistributed(self.window_encoder)\n",
        "        self.session_encoder = EncoderBlock(n_window, d_model, num_heads,\n",
        "                                            dff, num_sa_blocks=2, add_pe=True,\n",
        "                                            dropout_rate=dropout_rate)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.window_sequence(x)\n",
        "        return self.session_encoder(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nTBFpugUyus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLPClassifier(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_classes, hidden_layers = [128, 32]):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.layers = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(num_units, activation='relu') for num_units in hidden_layers]\n",
        "        )\n",
        "        self.final_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.final_layer(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JymbZtqkjAC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HARModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes, n_window, n_timesteps, d_model, num_heads, dff, dropout_rate):\n",
        "        super(HARModel, self).__init__()\n",
        "        self.data_transform = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(d_model, 1))\n",
        "        self.encoder = HSAEncoder(n_window, n_timesteps, d_model, num_heads, dff,dropout_rate)\n",
        "        self.classifier = MLPClassifier(num_classes)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.data_transform(x)\n",
        "        x = self.encoder(x)\n",
        "        return self.classifier(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu8Nliz42Cey",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-SEtee02BoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = HARModel(num_classes=7, n_window=40, n_timesteps=25,\n",
        "                 d_model=128, num_heads=8, dff=256, dropout_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwtAmh292fQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model.compile(tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyr2iUaIEM6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c0696333-de3e-4c7b-ba79-5a16d61f0a60"
      },
      "source": [
        "model.build((1, 40, 25, 6))\n",
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"har_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri multiple                  896       \n",
            "_________________________________________________________________\n",
            "hsa_encoder (HSAEncoder)     multiple                  793856    \n",
            "_________________________________________________________________\n",
            "mlp_classifier (MLPClassifie multiple                  20871     \n",
            "=================================================================\n",
            "Total params: 815,623\n",
            "Trainable params: 815,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6pXbUj33I_X",
        "colab_type": "code",
        "outputId": "7e9a9069-fee1-46af-ef84-06f8138545a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_dataset, epochs=50, validation_data=val_dataset)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "61/61 [==============================] - 23s 380ms/step - loss: 1.9995 - accuracy: 0.1647 - val_loss: 1.9236 - val_accuracy: 0.1066\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9225 - accuracy: 0.1726 - val_loss: 1.9460 - val_accuracy: 0.1348\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 22s 363ms/step - loss: 1.9477 - accuracy: 0.1260 - val_loss: 1.9467 - val_accuracy: 0.0564\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9479 - accuracy: 0.1468 - val_loss: 1.9498 - val_accuracy: 0.0294\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9530 - accuracy: 0.1493 - val_loss: 1.9450 - val_accuracy: 0.1409\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 22s 363ms/step - loss: 1.9411 - accuracy: 0.1309 - val_loss: 1.9450 - val_accuracy: 0.1471\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9456 - accuracy: 0.1429 - val_loss: 1.9459 - val_accuracy: 0.1471\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9455 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9454 - accuracy: 0.1522 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9453 - accuracy: 0.1527 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 22s 363ms/step - loss: 1.9452 - accuracy: 0.1522 - val_loss: 1.9458 - val_accuracy: 0.1409\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9451 - accuracy: 0.1527 - val_loss: 1.9458 - val_accuracy: 0.1409\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9450 - accuracy: 0.1534 - val_loss: 1.9458 - val_accuracy: 0.1409\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 22s 362ms/step - loss: 1.9450 - accuracy: 0.1522 - val_loss: 1.9458 - val_accuracy: 0.1409\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9449 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 22s 360ms/step - loss: 1.9449 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9448 - accuracy: 0.1522 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9448 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9447 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9447 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9447 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 22s 361ms/step - loss: 1.9447 - accuracy: 0.1524 - val_loss: 1.9459 - val_accuracy: 0.1409\n",
            "Epoch 23/50\n",
            "43/61 [====================>.........] - ETA: 5s - loss: 1.9435 - accuracy: 0.1581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-f3a2d22fcdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlxSuX8iMZsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}